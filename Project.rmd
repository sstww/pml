---
title: "Practical Machine Learning Project"
author: "Mark Xu"
date: "Saturday, July 25, 2015"
output: html_document
---

***EXECUTIVE SUMMARY

The goal of this project is to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants to predict whether they perform barbell lifts correctly and incorrectly in 5 different ways. Background information about the setup and data collection is available from the website here: http://groupware.les.inf.puc-rio.br/har (see the section on the Weight Lifting Exercise Dataset). 

*** DATA
Read the data into R for analysis:
```{r}
dtraining <- read.csv(file="https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv",head=TRUE,sep=",")
dtest<-read.csv(file="https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv",head=TRUE,sep=",")
c(dim(dtraining), dim(dtest))
summary(dtraining$classe)
```

The dataset has 160 variables and are divided into a 19622-record training data set and a 20-record testing dataset. The variable classe has five different classes, which is what we will be predicting on. Preliminary analysis shows that the data needs to be cleaned before being used in model building or testing. 

To reduce the number of features in the model, I would like to remove variables with nearly zero variance. I also remove varibles with largely missing data.  The step results in 102 variables being removed and 58 variables remaining.

```{r}
library(caret)
dtraining<-dtraining[,-nearZeroVar(dtraining)]
dim(dtraining)

mostlyNA<-sapply(dtraining, function(x) mean(is.na(x)))>0.95
dtraining<-dtraining[,mostlyNA==F]

```

***MODEL BUILDING

For assess out of sample error, I define training and test sub datasets from within the training dataset. 

```{r}
inTrain<-createDataPartition(y=dtraining$classe, p=0.70, list=FALSE)
subtraining<-dtraining[inTrain,]
subtest<-dtraining[-inTrain,]
dim(subtraining); dim(subtest)
```

I fit a Random Forest model, using 5-fold corss-validation to select optimal tuning parameters for the model.

```{r}
mod<-train(classe~., data=subtraining, method="rf", 
           trControl=trainControl(number=5, verboseIter=F))
```

Print the final model:

```{r}
mod$finalModel
```

There are 500 trees in the model with 40 variables tried at each split.  The OOB estimate of error rate is 0.12%.  

*** MODEL EVALUATION

```{r}
pred<-predict(mod, newdata=subtest)

confusionMatrix(subtest$classe, pred)
```

The accuracy is 99.97%, and thus the predicted accuracy for the out-of-sample error is 0.03%. With this level of accuracy, there is no need to test other model configurations. 

***Retraining the Selected Model

To furthur increase the accuracy on the test set, I retrain the selected model using the complete training data set.

```{r}
mod2<-train(classe~., data=dtraining, method="rf", 
           trControl=trainControl(number=5, verboseIter=F))
```

***TEST SET PREDICTIONS

This step is for using the retrained model to predict the label for hte observations in dtest data set, and write the predictions to individual files:

```{r}
pred2<-predict(mod2, newdata=dtest)
pred2<-as.character(pred2)
pml_write_files <- function(x) {
    n <- length(x)
    for(i in 1:n) {
        filename <- paste0("problem_id_", i, ".txt")
        write.table(x[i], file=filename, quote=F, row.names=F, col.names=F)
    }
}

pml_write_files(pred2)

```
